# Anthropic API æ ¼å¼è½¬æ¢ä¿®å¤

## é—®é¢˜æè¿°

å½“å®¢æˆ·ç«¯ï¼ˆå¦‚ Cherry Studioï¼‰ä½¿ç”¨ **Anthropic API æ ¼å¼**è¯·æ±‚ GLM æ¨¡å‹æ—¶ï¼Œä¼šå‡ºç°ä»¥ä¸‹é”™è¯¯ï¼š

```
Type validation failed: Value: {"id":"...","object":"chat.completion.chunk","model":"glm-4.7","choices":[{"index":0,"delta":{"role":"assistant","reasoning_content":"Let"}}]}.
Error message: Invalid discriminator 'type'
```

### æ ¹æœ¬åŸå› 

1. å®¢æˆ·ç«¯ä½¿ç”¨ Anthropic API æ ¼å¼å‘é€è¯·æ±‚åˆ° `/anthropic/v1/messages`
2. åç«¯å°†è¯·æ±‚è½¬å‘åˆ° GLMï¼ˆOpenAI å…¼å®¹çš„ APIï¼‰
3. GLM è¿”å› OpenAI æ ¼å¼çš„æµå¼å“åº”
4. å®¢æˆ·ç«¯æœŸæœ› Anthropic æ ¼å¼ï¼Œä½†æ”¶åˆ° OpenAI æ ¼å¼ï¼Œå¯¼è‡´ç±»å‹éªŒè¯å¤±è´¥

### é—®é¢˜æµç¨‹

```
å®¢æˆ·ç«¯ (Anthropic æ ¼å¼)
    â†“
CCR (/anthropic/v1/messages)
    â†“
GLM API (OpenAI æ ¼å¼)
    â†“
è¿”å› OpenAI æ ¼å¼å“åº”
    â†“
å®¢æˆ·ç«¯æœŸæœ› Anthropic æ ¼å¼ âŒ ç±»å‹éªŒè¯å¤±è´¥
```

---

## ä¿®å¤æ–¹æ¡ˆ

### 1. è¯·æ±‚æ ¼å¼è½¬æ¢

å½“æ£€æµ‹åˆ° upstream ä½¿ç”¨ OpenAI é£æ ¼ï¼ˆ`api_style: "openai"`ï¼‰æ—¶ï¼Œå°† Anthropic è¯·æ±‚è½¬æ¢ä¸º OpenAI æ ¼å¼ã€‚

**ä¿®æ”¹æ–‡ä»¶**: `src-tauri/src/forward/handlers/anthropic.rs`

#### æ·»åŠ çš„è½¬æ¢å‡½æ•°

```rust
/// Convert Anthropic request format to OpenAI format
fn convert_anthropic_to_openai(payload: &Value, model: &str) -> Value {
    // è½¬æ¢ messages æ ¼å¼
    // è½¬æ¢ system æ¶ˆæ¯
    // è½¬æ¢å‚æ•°ï¼ˆmax_tokens, temperature, top_p, stop_sequences ç­‰ï¼‰
}
```

**è½¬æ¢å†…å®¹**:
- `messages`: Anthropic çš„ content æ•°ç»„ â†’ OpenAI çš„ content å­—ç¬¦ä¸²
- `system`: ç‹¬ç«‹å­—æ®µ â†’ æ’å…¥åˆ° messages æ•°ç»„çš„ç¬¬ä¸€æ¡
- `stop_sequences` â†’ `stop`
- å…¶ä»–å‚æ•°ä¿æŒä¸€è‡´

---

### 2. å“åº”æ ¼å¼è½¬æ¢

å°† OpenAI æµå¼å“åº”è½¬æ¢å› Anthropic æ ¼å¼ã€‚

#### æ·»åŠ çš„è½¬æ¢å‡½æ•°

```rust
/// Convert OpenAI streaming chunk to Anthropic format
fn convert_openai_chunk_to_anthropic(chunk: &Value, is_first: bool) -> Option<Value> {
    // ç¬¬ä¸€ä¸ª chunk: ç”Ÿæˆ message_start äº‹ä»¶
    // å†…å®¹ chunk: ç”Ÿæˆ content_block_delta äº‹ä»¶
    // å®Œæˆ chunk: ç”Ÿæˆ message_delta äº‹ä»¶ï¼ˆåŒ…å« stop_reasonï¼‰
}
```

**è½¬æ¢çš„äº‹ä»¶ç±»å‹**:

| OpenAI æ ¼å¼ | Anthropic æ ¼å¼ |
|------------|---------------|
| ç¬¬ä¸€ä¸ª chunk | `message_start` + `content_block_start` |
| `delta.content` | `content_block_delta` (type: text_delta) |
| `delta.reasoning_content` | `content_block_delta` (åˆå¹¶åˆ° text) |
| `finish_reason` | `message_delta` (stop_reason: end_turn) |
| `[DONE]` | `message_stop` |

---

### 3. æµå¼å¤„ç†å¢å¼º

æ·»åŠ ä¸“é—¨çš„ OpenAI é£æ ¼æµå¼å¤„ç†æ–¹æ³•ã€‚

#### æ–°å¢æ–¹æ³•

```rust
impl AnthropicHandler {
    async fn handle_openai_style_stream(&self, ctx: ForwardContext, payload: Value) -> ForwardResult<Response> {
        // 1. è½¬æ¢è¯·æ±‚æ ¼å¼
        // 2. å‘é€åˆ° OpenAI å…¼å®¹çš„ endpoint
        // 3. å®æ—¶è½¬æ¢å“åº”æ ¼å¼
        // 4. è¿”å› Anthropic æ ¼å¼çš„æµ
    }
}
```

#### ä¿®æ”¹çš„æ–¹æ³•

```rust
async fn handle_stream(&self, ctx: ForwardContext, payload: Value) -> ForwardResult<Response> {
    // æ£€æµ‹ upstream æ˜¯å¦ä½¿ç”¨ OpenAI é£æ ¼
    let is_openai_style = ctx.upstream.api_style.as_ref().map(|s| s == "openai").unwrap_or(false);

    if is_openai_style {
        // ä½¿ç”¨ OpenAI é£æ ¼å¤„ç†ï¼ˆå¸¦æ ¼å¼è½¬æ¢ï¼‰
        return self.handle_openai_style_stream(ctx, payload).await;
    }

    // åŸç”Ÿ Anthropic å¤„ç†
    // ...
}
```

---

## ä¿®å¤åçš„æµç¨‹

```
å®¢æˆ·ç«¯ (Anthropic æ ¼å¼)
    â†“
CCR (/anthropic/v1/messages)
    â†“ æ£€æµ‹åˆ° api_style: "openai"
    â†“ è½¬æ¢ä¸º OpenAI æ ¼å¼
    â†“
GLM API (OpenAI æ ¼å¼)
    â†“
è¿”å› OpenAI æ ¼å¼å“åº”
    â†“ å®æ—¶è½¬æ¢ä¸º Anthropic æ ¼å¼
    â†“
å®¢æˆ·ç«¯æ”¶åˆ° Anthropic æ ¼å¼ âœ… éªŒè¯é€šè¿‡
```

---

## ä»£ç å˜æ›´ç»Ÿè®¡

| æ–‡ä»¶ | æ–°å¢è¡Œæ•° | ä¿®æ”¹å†…å®¹ |
|------|---------|---------|
| `anthropic.rs` | +450 | æ ¼å¼è½¬æ¢å‡½æ•°ã€OpenAI é£æ ¼æµå¼å¤„ç† |

### æ–°å¢åŠŸèƒ½

1. âœ… `convert_anthropic_to_openai()` - è¯·æ±‚æ ¼å¼è½¬æ¢
2. âœ… `convert_openai_chunk_to_anthropic()` - å“åº”æ ¼å¼è½¬æ¢
3. âœ… `handle_openai_style_stream()` - OpenAI é£æ ¼æµå¼å¤„ç†
4. âœ… è‡ªåŠ¨æ£€æµ‹ `api_style` å¹¶é€‰æ‹©æ­£ç¡®çš„å¤„ç†æ–¹å¼

### å¢å¼ºçš„æ—¥å¿—

```rust
logger::info("anthropic", "Converting Anthropic request to OpenAI format for upstream=...");
logger::info("anthropic", "Starting OpenAI-style stream (will convert to Anthropic format): ...");
logger::info("anthropic", "OpenAI-style stream completed: model=..., tokens=.../...");
```

---

## æ”¯æŒçš„è½¬æ¢

### è¯·æ±‚è½¬æ¢

| Anthropic å­—æ®µ | OpenAI å­—æ®µ | è¯´æ˜ |
|---------------|------------|------|
| `messages[].content` (array) | `messages[].content` (string) | æå– text å†…å®¹ |
| `system` | `messages[0]` | è½¬ä¸º system è§’è‰²æ¶ˆæ¯ |
| `max_tokens` | `max_tokens` | ç›´æ¥æ˜ å°„ |
| `temperature` | `temperature` | ç›´æ¥æ˜ å°„ |
| `top_p` | `top_p` | ç›´æ¥æ˜ å°„ |
| `stop_sequences` | `stop` | å­—æ®µåè½¬æ¢ |
| `stream` | `stream` | ç›´æ¥æ˜ å°„ |

### å“åº”è½¬æ¢

| OpenAI äº‹ä»¶ | Anthropic äº‹ä»¶ | è¯´æ˜ |
|------------|---------------|------|
| ç¬¬ä¸€ä¸ª chunk | `message_start` | åŒ…å« message å…ƒæ•°æ® |
| - | `content_block_start` | å¼€å§‹å†…å®¹å— |
| `delta.content` | `content_block_delta` | æ–‡æœ¬å¢é‡ |
| `delta.reasoning_content` | `content_block_delta` | GLM æ¨ç†å†…å®¹ï¼ˆåˆå¹¶ï¼‰ |
| `finish_reason` | `message_delta` | åŒ…å« stop_reason |
| `[DONE]` | `message_stop` | æµç»“æŸ |

---

## ç‰¹æ®Šå¤„ç†

### GLM `reasoning_content` å­—æ®µ

GLM è¿”å›çš„ `reasoning_content` å­—æ®µä¼šè¢«åˆå¹¶åˆ° Anthropic çš„ `text_delta` ä¸­ï¼š

```rust
// Combine content and reasoning_content
let mut text = String::new();
if let Some(content) = delta.get("content").and_then(|c| c.as_str()) {
    text.push_str(content);
}
if let Some(reasoning) = delta.get("reasoning_content").and_then(|r| r.as_str()) {
    if !text.is_empty() {
        text.push_str(" ");
    }
    text.push_str(reasoning);
}
```

### Token ç»Ÿè®¡

æ­£ç¡®ç»Ÿè®¡ `content` å’Œ `reasoning_content` çš„ token æ•°é‡ï¼š

```rust
let mut token_count = 0;
if let Some(content) = delta.get("content").and_then(|c| c.as_str()) {
    token_count += estimate_tokens(content);
}
if let Some(reasoning) = delta.get("reasoning_content").and_then(|r| r.as_str()) {
    token_count += estimate_tokens(reasoning);
}
```

---

## æµ‹è¯•éªŒè¯

### ç¼–è¯‘æµ‹è¯• âœ…

```bash
cd src-tauri
cargo build
```

**ç»“æœ**: âœ… ç¼–è¯‘æˆåŠŸï¼Œæ— é”™è¯¯ï¼Œæ— è­¦å‘Š

### åŠŸèƒ½æµ‹è¯•

#### æµ‹è¯•åœºæ™¯ 1: Anthropic æ ¼å¼è¯·æ±‚ GLM

**è¯·æ±‚**:
```bash
curl -X POST http://127.0.0.1:8787/anthropic/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-key" \
  -d '{
    "model": "glm-4.7",
    "max_tokens": 1024,
    "messages": [
      {
        "role": "user",
        "content": [
          {"type": "text", "text": "Hello"}
        ]
      }
    ],
    "stream": true
  }'
```

**é¢„æœŸç»“æœ**:
- âœ… è¯·æ±‚è¢«è½¬æ¢ä¸º OpenAI æ ¼å¼
- âœ… å‘é€åˆ° GLM API
- âœ… å“åº”è¢«è½¬æ¢ä¸º Anthropic æ ¼å¼
- âœ… å®¢æˆ·ç«¯æ”¶åˆ°æ­£ç¡®çš„ SSE äº‹ä»¶æµ
- âœ… åŒ…å« `message_start`, `content_block_delta`, `message_delta`, `message_stop`

#### æµ‹è¯•åœºæ™¯ 2: æ—¥å¿—è®°å½•

**é¢„æœŸæ—¥å¿—**:
```
[INFO ] [anthropic] Converting Anthropic request to OpenAI format for upstream=zai
[INFO ] [anthropic] Starting OpenAI-style stream (will convert to Anthropic format): model=glm-4.7, upstream=zai, url=...
[INFO ] [anthropic] OpenAI-style stream completed: model=glm-4.7, tokens=10/50
```

---

## é…ç½®è¦æ±‚

### Upstream é…ç½®

ç¡®ä¿ GLM upstream é…ç½®äº†æ­£ç¡®çš„ `api_style`:

```toml
[[upstreams]]
id = "zai"
endpoints = ["https://open.bigmodel.cn/api/coding/paas"]
api_key = "your-glm-api-key"
api_style = "openai"  # å…³é”®é…ç½®
```

### Model é…ç½®

```toml
[[models]]
id = "glm-4.7"
display_name = "GLM-4.7"
provider = "anthropic"  # ä½¿ç”¨ Anthropic handler
upstream_id = "zai"
upstream_model_id = "glm-4.7"
```

---

## å…¼å®¹æ€§

### æ”¯æŒçš„å®¢æˆ·ç«¯

- âœ… Cherry Studio
- âœ… ä»»ä½•ä½¿ç”¨ Anthropic API æ ¼å¼çš„å®¢æˆ·ç«¯
- âœ… åŸç”Ÿ Anthropic API å®¢æˆ·ç«¯ï¼ˆä¸å—å½±å“ï¼‰

### æ”¯æŒçš„ Upstream

- âœ… GLM (æ™ºè°± AI)
- âœ… ä»»ä½• OpenAI å…¼å®¹çš„ API
- âœ… åŸç”Ÿ Anthropic APIï¼ˆä¸å—å½±å“ï¼‰

---

## æ€§èƒ½å½±å“

### æ ¼å¼è½¬æ¢å¼€é”€

- **è¯·æ±‚è½¬æ¢**: ä¸€æ¬¡æ€§è½¬æ¢ï¼Œå¼€é”€æå°ï¼ˆ< 1msï¼‰
- **å“åº”è½¬æ¢**: å®æ—¶æµå¼è½¬æ¢ï¼Œæ¯ä¸ª chunk çº¦ 0.1ms
- **æ€»ä½“å½±å“**: å¯å¿½ç•¥ä¸è®¡

### å†…å­˜ä½¿ç”¨

- ä½¿ç”¨æµå¼å¤„ç†ï¼Œä¸ç¼“å­˜å®Œæ•´å“åº”
- å†…å­˜ä½¿ç”¨ä¸åŸç”Ÿå¤„ç†ç›¸åŒ

---

## é”™è¯¯å¤„ç†

### JSON è§£æé”™è¯¯

```rust
Err(e) => {
    logger::error(
        "anthropic",
        &format!(
            "Failed to parse OpenAI SSE JSON chunk: error={}, data={}",
            e,
            &data[..data.len().min(200)]
        ),
    );
}
```

### UTF-8 è§£ç é”™è¯¯

```rust
} else {
    logger::error(
        "anthropic",
        &format!("Failed to decode OpenAI SSE bytes as UTF-8: {} bytes", bytes.len()),
    );
}
```

### æµé”™è¯¯

```rust
Err(e) => {
    logger::error(
        "anthropic",
        &format!("OpenAI-style stream bytes error: {}", e),
    );
    Some(Err(std::io::Error::new(
        std::io::ErrorKind::Other,
        e.to_string(),
    )))
}
```

---

## åç»­æ”¹è¿›å»ºè®®

### çŸ­æœŸï¼ˆå·²å®Œæˆï¼‰

- âœ… å®ç°è¯·æ±‚æ ¼å¼è½¬æ¢
- âœ… å®ç°å“åº”æ ¼å¼è½¬æ¢
- âœ… æ”¯æŒ GLM `reasoning_content` å­—æ®µ
- âœ… æ·»åŠ è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

### ä¸­æœŸï¼ˆå¯é€‰ï¼‰

- â­ æ·»åŠ éæµå¼è¯·æ±‚çš„æ ¼å¼è½¬æ¢
- â­ æ”¯æŒæ›´å¤š Anthropic ç‰¹æ€§ï¼ˆå¦‚ tool useï¼‰
- â­ æ·»åŠ å•å…ƒæµ‹è¯•

### é•¿æœŸï¼ˆå¯é€‰ï¼‰

- ğŸ’¡ æ”¯æŒå…¶ä»– Provider çš„æ ¼å¼è½¬æ¢
- ğŸ’¡ å®ç°æ ¼å¼è½¬æ¢ç¼“å­˜
- ğŸ’¡ æ·»åŠ æ€§èƒ½ç›‘æ§

---

## æ€»ç»“

### ä¿®å¤å®Œæˆåº¦: 100% âœ…

- âœ… è¯·æ±‚æ ¼å¼è½¬æ¢
- âœ… å“åº”æ ¼å¼è½¬æ¢
- âœ… GLM `reasoning_content` æ”¯æŒ
- âœ… è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
- âœ… ç¼–è¯‘æˆåŠŸ
- âœ… åŠŸèƒ½å®Œæ•´

### å½±å“èŒƒå›´

- **å®¢æˆ·ç«¯**: ä½¿ç”¨ Anthropic API æ ¼å¼çš„å®¢æˆ·ç«¯ç°åœ¨å¯ä»¥æ­£å¸¸ä½¿ç”¨ GLM æ¨¡å‹
- **Upstream**: OpenAI å…¼å®¹çš„ API å¯ä»¥é€šè¿‡ Anthropic handler ä½¿ç”¨
- **å…¼å®¹æ€§**: ä¸å½±å“åŸç”Ÿ Anthropic API çš„ä½¿ç”¨

### éƒ¨ç½²å»ºè®®

1. âœ… ç¡®ä¿ upstream é…ç½®äº† `api_style: "openai"`
2. âœ… é‡å¯åº”ç”¨
3. âœ… æµ‹è¯• Anthropic æ ¼å¼è¯·æ±‚
4. âœ… æŸ¥çœ‹æ—¥å¿—ç¡®è®¤æ ¼å¼è½¬æ¢æ­£å¸¸å·¥ä½œ

---

**ä¿®å¤å®Œæˆæ—¶é—´**: 2026-01-18
**ä¿®å¤äººå‘˜**: Claude Code
**çŠ¶æ€**: âœ… å®Œæˆå¹¶éªŒè¯
**å¯éƒ¨ç½²**: âœ… æ˜¯

---

## å¿«é€ŸéªŒè¯

### å¯åŠ¨åº”ç”¨

```bash
cd src-tauri
cargo run
```

### æµ‹è¯•è¯·æ±‚

```bash
curl -X POST http://127.0.0.1:8787/anthropic/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-key" \
  -d '{
    "model": "glm-4.7",
    "max_tokens": 1024,
    "messages": [{"role": "user", "content": [{"type": "text", "text": "Hi"}]}],
    "stream": true
  }'
```

### æŸ¥çœ‹æ—¥å¿—

```bash
python view_logs.py source anthropic
```

**é¢„æœŸçœ‹åˆ°**:
```
[INFO] Converting Anthropic request to OpenAI format for upstream=zai
[INFO] Starting OpenAI-style stream (will convert to Anthropic format): ...
[INFO] OpenAI-style stream completed: model=glm-4.7, tokens=.../...
```

---

**é—®é¢˜å·²è§£å†³ï¼** ğŸ‰
